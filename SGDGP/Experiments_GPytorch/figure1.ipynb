{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import gpytorch\n",
    "from gpytorch.models import ExactGP\n",
    "from torch.distributions import Normal, MultivariateNormal\n",
    "from matplotlib import pyplot as plt\n",
    "from skgpytorch.models import ExactGPRegressor\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel\n",
    "from gpytorch.constraints import GreaterThan\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1024\n",
    "torch.manual_seed(0)\n",
    "x_dist = Normal(torch.tensor([0.0]), torch.tensor([5.0]))\n",
    "X = x_dist.sample((N,))\n",
    "K = ScaleKernel(RBFKernel())\n",
    "K.base_kernel.lengthscale = 0.5\n",
    "K.outputscale = 4.0\n",
    "K_ = K(X,X) + (1**2)*torch.eye(len(X))\n",
    "dist = MultivariateNormal(torch.zeros((N,)),K_.evaluate())\n",
    "Y = dist.sample()\n",
    "plt.scatter(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDGP(ExactGPRegressor):\n",
    "    def __init__(self, train_x, train_y, mll):\n",
    "        super().__init__(train_x, train_y, mll)\n",
    "    \n",
    "    def sgd_fit(self, batch_size, lr, n_epochs, n_restarts, thetas, random_state):\n",
    "\n",
    "        torch.manual_seed(random_state)\n",
    "        ## creating nn_indices\n",
    "        neigh = NearestNeighbors(n_neighbors=batch_size, algorithm='kd_tree')\n",
    "        neigh.fit(self.train_x.cpu())\n",
    "        _, neigh_idx = neigh.kneighbors(self.train_x.cpu(), batch_size)\n",
    "\n",
    "        if (len(self.train_x) % batch_size  == 0):\n",
    "          num_batches = int(len(self.train_x)/batch_size)\n",
    "        else:\n",
    "          num_batches = int((len(self.train_x)/batch_size)) + 1\n",
    "\n",
    "        least_loss = float(\"inf\")\n",
    "        best_mll_state = None\n",
    "        self.history[\"total_loss\"] = []\n",
    "        self.history[\"signal_var\"] = []\n",
    "        self.history[\"noise_var\"] = []\n",
    "        self.mll.train()\n",
    "        for restart in range(n_restarts):\n",
    "            self.optimizer = torch.optim.SGD(self.mll.parameters(), lr=lr)\n",
    "            # self.optimizer = torch.optim.Adam(self.mll.parameters(), lr=0.1)\n",
    "            self.history[\"total_loss\"].append([])\n",
    "            self.history[\"signal_var\"].append([])\n",
    "            self.history[\"noise_var\"].append([])\n",
    "\n",
    "            # Resetting the model for restarts\n",
    "            if restart > 0:  \n",
    "                for param in self.mll.parameters():\n",
    "                    torch.nn.init.normal_(param, mean=0.0, std=1.0)\n",
    "            self.mll.model.initialize(**thetas)\n",
    "            self.mll.model.covar_module.base_kernel.raw_lengthscale.requires_grad = False\n",
    "            for epoch in range(1, n_epochs+1):\n",
    "                loss = 0\n",
    "                for iteration in range(1, num_batches+1):\n",
    "           \n",
    "                    idx = torch.tensor((iteration - 1)%self.train_x.shape[0])\n",
    "                    indices = neigh_idx[idx,]\n",
    "                    X_batch = self.train_x[indices,]\n",
    "                    y_batch = self.train_y[indices,]\n",
    "\n",
    "                    self.optimizer.zero_grad()\n",
    "                    batch_loss = self.loss_func(X_batch, y_batch)\n",
    "                    self.history[\"signal_var\"][restart].append(self.mll.model.covar_module.outputscale.item())\n",
    "                    self.history[\"noise_var\"][restart].append(self.mll.likelihood.noise_covar.noise.item())\n",
    "\n",
    "                    batch_loss.backward()\n",
    "                    loss += batch_loss.item()\n",
    "\n",
    "                    self.mll.model.covar_module.raw_outputscale.grad*= batch_size/(3*torch.log(torch.tensor(batch_size)))\n",
    "\n",
    "                    self.optimizer.step()\n",
    "                    for group in self.optimizer.param_groups:\n",
    "                        group['lr'] = lr/(iteration)\n",
    "                \n",
    "                loss = loss / num_batches\n",
    "                self.history[\"total_loss\"][restart].append(loss)\n",
    "\n",
    "            # Check if best loss\n",
    "            if loss < least_loss:\n",
    "                self.best_restart = restart\n",
    "                least_loss = loss\n",
    "                best_mll_state = self.mll.state_dict()\n",
    "\n",
    "        # Load the best model\n",
    "        if best_mll_state is not None:\n",
    "            self.mll.load_state_dict(best_mll_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1024\n",
    "batch_size =128\n",
    "theta1 = {'likelihood.noise_covar.noise': torch.tensor(3).to(device),\n",
    "        'covar_module.base_kernel.lengthscale': torch.tensor(0.5).to(device),\n",
    "        'covar_module.outputscale': torch.tensor(5).to(device),}\n",
    "theta2 = {'likelihood.noise_covar.noise': torch.tensor(3.5).to(device),\n",
    "        'covar_module.base_kernel.lengthscale': torch.tensor(0.5).to(device),\n",
    "        'covar_module.outputscale': torch.tensor(2.5).to(device),}\n",
    "theta3 = {'likelihood.noise_covar.noise': torch.tensor(2.7).to(device),\n",
    "        'covar_module.base_kernel.lengthscale': torch.tensor(0.5).to(device),\n",
    "        'covar_module.outputscale': torch.tensor(2.5).to(device),}\n",
    "\n",
    "thetas = [theta1,theta2,theta3]\n",
    "lrs = [3,3,1]\n",
    "fig,ax = plt.subplots(1,3,figsize=(30,6))\n",
    "\n",
    "for j in range(len(thetas)):\n",
    "    theta = thetas[j]\n",
    "    for i in range(10):\n",
    "        lr = lrs[j]\n",
    "        torch.manual_seed(0)\n",
    "        x_dist = Normal(torch.tensor([0.0]), torch.tensor([5.0]))\n",
    "        X = x_dist.sample((N,))\n",
    "        K = ScaleKernel(RBFKernel())\n",
    "        K.base_kernel.lengthscale = 0.5\n",
    "        K.outputscale = 1.0\n",
    "        cov = K(X,X) + (0.5)*(torch.eye(len(X)))\n",
    "        dist = MultivariateNormal(torch.zeros((1024)),cov.evaluate())\n",
    "        torch.manual_seed(i+1)\n",
    "        Y = dist.sample()\n",
    "        \n",
    "        kernel = ScaleKernel(RBFKernel(ard_num_dims=X.shape[1])).to(device)\n",
    "        model = SGDGP(X.to(device), Y.to(device), kernel).to(device)\n",
    "        model.sgd_fit(batch_size,lr,50,1,thetas = theta, random_state=0)\n",
    "        ax[j].plot(pd.Series(model.history['signal_var'][0]),linestyle='dashed',linewidth=1.5) \n",
    "        ax[j].plot(pd.Series(model.history['noise_var'][0]),linestyle='dotted',linewidth=1.5)\n",
    "    ax[j].axhline(y = 1.0, color = 'black', linestyle = 'dashed')\n",
    "    ax[j].axhline(y = 0.5, color = 'red', linestyle = ':')\n",
    "    ax[j].axhline(y = 1.5, color = 'black', linestyle = 'dashed')\n",
    "    ax[j].set_xlabel('Iteration (k)')\n",
    "    ax[j].set_ylabel('O(k)')\n",
    "    ax[j].set_title(f'({theta[\"covar_module.outputscale\"]},{round(theta[\"likelihood.noise_covar.noise\"].item(),2)})')\n",
    "    # ax[j].set_xticks([0,50,100,150,200])\n",
    "    ax[j].set_yticks([0,1,2,3,4,5])\n",
    "    ax[j].grid()\n",
    "\n",
    "plt.savefig('figure1_testing.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('SGDGP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8ac03bc53b81f274766a4c3d65a8bb144021040a3f00168f019aaf215aad8e7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
